# Cloudflare Worker for Repository Analysis

This Cloudflare Worker fetches popular GitHub repositories from the popular.forgithub.com API, analyzes them using the Deepseek LLM to categorize and summarize them, and caches the results in KV storage.

## Performance Optimizations

This API includes several performance optimizations:

1. **Repository Analysis Caching**: Each repository's category and summary are cached in KV storage for 24 hours
2. **Popular Repositories Caching**: The list of repositories from popular.forgithub.com is cached for 24 hours
3. **Smart Cache Refresh**: Cache automatically refreshes after 1:30 AM UTC when popular.forgithub.com updates
4. **Parallel Processing**: Multiple repositories are analyzed concurrently
5. **Response Size Optimization**: Only essential information is returned, reducing bandwidth usage

## File Structure

```
src/
├── index.ts         # Main entry point and request handler
├── service.ts       # Service layer for repository data and analysis orchestration
├── llm.ts           # LLM integration for repository analysis
├── cache.ts         # KV cache operations
├── transformer.ts   # Data transformation for simplified output
└── types.ts         # TypeScript type definitions
```

## Setup Instructions

1. **Create a Cloudflare Worker project**:
   ```bash
   npm create cloudflare@latest popular-repos-analyzer
   cd popular-repos-analyzer
   ```
   
2. **Install required dependencies**:
   ```bash
   npm install @cloudflare/workers-types
   ```

3. **Create a KV namespace for caching**:
   ```bash
   wrangler kv:namespace create "REPO_CACHE"
   ```
   Then copy the resulting ID to your wrangler.toml file.

4. **Set your Deepseek API key as a secret**:
   ```bash
   wrangler secret put LLM_API_KEY
   ```

5. **Deploy the worker**:
   ```bash
   wrangler publish
   ```

## API Usage

### Basic Request

Make a GET request to the worker URL:

```
GET https://<your-worker>.<your-subdomain>.workers.dev/
```

By default, this returns the first 5 popular repositories with added analysis.

### Customizing the Limit

You can specify how many repositories to return using the `limit` parameter:

```
GET https://<your-worker>.<your-subdomain>.workers.dev/?limit=10
```

This would return the top 10 repositories with analysis.

### Response Format

The API returns a simplified JSON response with only the essential repository information:

```json
{
  "repositories": [
    {
      "name": "repo-name",
      "full_name": "owner/repo-name",
      "description": "Repository description",
      "owner": {
        "login": "owner-name",
        "avatar_url": "https://avatars.githubusercontent.com/u/12345?v=4",
        "type": "Organization"
      },
      "homepage": "https://repo-website.com",
      "created_at": "2025-01-01T00:00:00Z",
      "updated_at": "2025-01-15T00:00:00Z",
      "stargazers_count": 1500,
      "forks_count": 250,
      "language": "JavaScript",
      "license": {
        "name": "MIT License"
      },
      "topics": [
        "javascript", 
        "frontend", 
        "ui"
      ],
      "category": "Frontend",
      "summary": "A concise technical summary of the repository generated by Deepseek LLM."
    },
    // More repositories...
  ],
  "count": 5,
  "total_available": 30,
  "limit": 5,
  "timestamp": "2025-05-15T10:15:30.123Z"
}
```

## Key Features

- **Repository Analysis**: Automatically categorizes repositories and generates concise summaries
- **Caching**: Uses KV storage to cache analysis results for 24 hours
- **Error Handling**: Gracefully handles failures with fallbacks
- **Parallel Processing**: Analyzes multiple repositories concurrently
- **Retry Logic**: Implements exponential backoff for LLM API calls
- **Customizable Limit**: Control how many repositories are returned
- **Simplified Output**: Returns only essential repository information

## Configuration

You can customize the following parameters in the respective files:

- **LLM Settings** (`llm.ts`):
  - Change the LLM provider, model, token limits
  - Modify the categorization prompt and categories
  - Adjust retry settings
  
- **Cache Settings** (`cache.ts`):
  - Adjust the TTL for cached analyses

- **Response Format** (`transformer.ts`):
  - Modify which fields are included in the simplified output

## Monitoring and Debugging

- View real-time logs:
  ```bash
  wrangler tail
  ```

- Monitor performance in the Cloudflare Dashboard:
  - Workers & Pages > your-worker-name